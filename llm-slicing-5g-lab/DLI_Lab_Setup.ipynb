{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start 5G Network Simulator\n",
    "\n",
    "In this DLI you will use an Agentic Generative AI solution to solve a bandwidth allocation problem. The lab will consist of two different parts. In the first part, the lab will show you how to setup an open source 5G Network Lab consisting of the following parts:\n",
    "- 5G Core Lab simulation by Open Air Interface: https://openairinterface.org/oai-5g-core-network-project/\n",
    "- FlexRIC that will be connected to the gNodeB and will be used to change the bandwidth allocation for each slice in the gNodeB\n",
    "- RAN Lab composed by a gNodeB and two Use Equipment simulation components from Open Air OAI Softmode: https://github.com/simula/openairinterface5g/blob/dreibh/simulamet-testbed/doc/RUNMODEM.md\n",
    "- Traffic generation over the Open Air network simulator using Iperf Tool: https://iperf.fr/\n",
    "\n",
    "The Lab setup will start with the initialization of the 5G Core Network, then we will set up the gNodeB and the RIC connecting both via the E1 protocol. We will attach two UEs to the 5G network, each UE1 will have its own slice as seen in the diagram. Once UEs are functional, we will use the Iperf tool to generate traffic. First we will set up the Iperf server on the OAI External Network connected by the User Plane Function UPF.  Then we will use the Iperf Client to generate traffic against the External Network using the UEs connection. \n",
    "\n",
    "![5G Lab](./5glab.png)\n",
    "\n",
    "In this Jupyter Notebook we will set the lab for the experiment. In a separate Jupyter Notebook we will build the Agentic Workflow for the experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Requirements\n",
    "In this first cell we will install the requirements for the Blueprint and we will restart the kernel, so you will need to press \"yes\" to the window that will pop up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target executable: /home/ubuntu/.venv/bin/python3\n",
      "pip not found. Installing in venv...\n",
      "Downloaded get-pip.py\n",
      "pip installed successfully in venv.\n",
      "Cleaned up get-pip.py\n",
      "\n",
      "After restart, run: !{executable} -m pip --version\n"
     ]
    }
   ],
   "source": [
    "#This cell installs pip in this Jupyter instance if not installed yet\n",
    "import sys\n",
    "import subprocess\n",
    "import urllib.request\n",
    "import os\n",
    "\n",
    "executable = sys.executable  # Points to /home/ubuntu/.venv/bin/python3\n",
    "print(f\"Target executable: {executable}\")\n",
    "\n",
    "# Check if pip is already installed\n",
    "try:\n",
    "    subprocess.check_call([executable, '-m', 'pip', '--version'], \n",
    "                          stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "    print(\"pip is already installed in the venv.\")\n",
    "except (subprocess.CalledProcessError, FileNotFoundError):\n",
    "    print(\"pip not found. Installing in venv...\")\n",
    "\n",
    "    # Download get-pip.py (official bootstrapper)\n",
    "    url = 'https://bootstrap.pypa.io/get-pip.py'\n",
    "    try:\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            with open('get-pip.py', 'wb') as f:\n",
    "                f.write(response.read())\n",
    "        print(\"Downloaded get-pip.py\")\n",
    "\n",
    "        # Install pip in the venv (no --user; installs to venv's site-packages)\n",
    "        result = subprocess.run([executable, 'get-pip.py'], \n",
    "                                capture_output=True, text=True)\n",
    "        if result.returncode == 0:\n",
    "            print(\"pip installed successfully in venv.\")\n",
    "        else:\n",
    "            print(f\"Installation error: {result.stderr}\")\n",
    "\n",
    "        # Clean up\n",
    "        os.remove('get-pip.py')\n",
    "        print(\"Cleaned up get-pip.py\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during download/install: {e}\")\n",
    "\n",
    "# Quick verification (run this after restarting kernel)\n",
    "print(\"\\nAfter restart, run: !{executable} -m pip --version\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "The following additional packages will be installed:\n",
      "  libiperf0 libsctp1\n",
      "Suggested packages:\n",
      "  lksctp-tools\n",
      "The following NEW packages will be installed:\n",
      "  iperf3 libiperf0 libsctp1\n",
      "0 upgraded, 3 newly installed, 0 to remove and 218 not upgraded.\n",
      "Need to get 106 kB of archives.\n",
      "After this operation, 346 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsctp1 amd64 1.0.19+dfsg-1build1 [9370 B]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libiperf0 amd64 3.9-1+deb11u1build0.22.04.1 [81.6 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 iperf3 amd64 3.9-1+deb11u1build0.22.04.1 [14.6 kB]\n",
      "Fetched 106 kB in 0s (247 kB/s)  \u001b[0m\u001b[33m\n",
      "\n",
      "\u001b7\u001b[0;23r\u001b8\u001b[1ASelecting previously unselected package libsctp1:amd64.\n",
      "(Reading database ... 145863 files and directories currently installed.)\n",
      "Preparing to unpack .../libsctp1_1.0.19+dfsg-1build1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  0%]\u001b[49m\u001b[39m [..........................................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  8%]\u001b[49m\u001b[39m [####......................................................] \u001b8Unpacking libsctp1:amd64 (1.0.19+dfsg-1build1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 15%]\u001b[49m\u001b[39m [########..................................................] \u001b8Selecting previously unselected package libiperf0:amd64.\n",
      "Preparing to unpack .../libiperf0_3.9-1+deb11u1build0.22.04.1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 23%]\u001b[49m\u001b[39m [#############.............................................] \u001b8Unpacking libiperf0:amd64 (3.9-1+deb11u1build0.22.04.1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 31%]\u001b[49m\u001b[39m [#################.........................................] \u001b8Selecting previously unselected package iperf3.\n",
      "Preparing to unpack .../iperf3_3.9-1+deb11u1build0.22.04.1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 38%]\u001b[49m\u001b[39m [######################....................................] \u001b8Unpacking iperf3 (3.9-1+deb11u1build0.22.04.1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 46%]\u001b[49m\u001b[39m [##########################................................] \u001b8Setting up libsctp1:amd64 (1.0.19+dfsg-1build1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 54%]\u001b[49m\u001b[39m [###############################...........................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 62%]\u001b[49m\u001b[39m [###################################.......................] \u001b8Setting up libiperf0:amd64 (3.9-1+deb11u1build0.22.04.1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 69%]\u001b[49m\u001b[39m [########################################..................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 77%]\u001b[49m\u001b[39m [############################################..............] \u001b8Setting up iperf3 (3.9-1+deb11u1build0.22.04.1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 85%]\u001b[49m\u001b[39m [#################################################.........] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 92%]\u001b[49m\u001b[39m [#####################################################.....] \u001b8Processing triggers for man-db (2.10.2-1) ...\n",
      "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
      "\n",
      "\u001b7\u001b[0;24r\u001b8\u001b[1A\u001b[JNEEDRESTART-VER: 3.5\n",
      "NEEDRESTART-KCUR: 5.15.0-126-generic\n",
      "NEEDRESTART-KEXP: 5.15.0-126-generic\n",
      "NEEDRESTART-KSTA: 1\n",
      "NEEDRESTART-SVC: dbus.service\n",
      "NEEDRESTART-SVC: networkd-dispatcher.service\n",
      "NEEDRESTART-SVC: polkit.service\n",
      "Collecting colorama==0.4.6 (from -r ../requirements.txt (line 1))\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Collecting colorlog==6.9.0 (from -r ../requirements.txt (line 2))\n",
      "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting python-gitlab==1.0.2 (from -r ../requirements.txt (line 3))\n",
      "  Downloading python-gitlab-1.0.2.tar.gz (112 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting gpudb==7.2.2.7 (from -r ../requirements.txt (line 4))\n",
      "  Downloading gpudb-7.2.2.7-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
      "Collecting ipython==8.27.0 (from -r ../requirements.txt (line 5))\n",
      "  Downloading ipython-8.27.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting langchain_core==0.3.75 (from -r ../requirements.txt (line 6))\n",
      "  Downloading langchain_core-0.3.75-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting langchain_nvidia_ai_endpoints==0.3.9 (from -r ../requirements.txt (line 7))\n",
      "  Downloading langchain_nvidia_ai_endpoints-0.3.9-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting langgraph==0.3.34 (from -r ../requirements.txt (line 8))\n",
      "  Downloading langgraph-0.3.34-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting matplotlib==3.10.1 (from -r ../requirements.txt (line 9))\n",
      "  Downloading matplotlib-3.10.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting numpy==1.26.4 (from -r ../requirements.txt (line 10))\n",
      "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting pandas==2.2.3 (from -r ../requirements.txt (line 11))\n",
      "  Downloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "Collecting paramiko==3.5.1 (from -r ../requirements.txt (line 12))\n",
      "  Downloading paramiko-3.5.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: pexpect==4.9.0 in /home/ubuntu/.venv/lib/python3.12/site-packages (from -r ../requirements.txt (line 13)) (4.9.0)\n",
      "Collecting pymysql==1.1.1 (from -r ../requirements.txt (line 14))\n",
      "  Downloading PyMySQL-1.1.1-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting pyroute2==0.9.2 (from -r ../requirements.txt (line 15))\n",
      "  Downloading pyroute2-0.9.2-py3-none-any.whl.metadata (7.7 kB)\n",
      "Collecting pyserial==3.5 (from -r ../requirements.txt (line 16))\n",
      "  Downloading pyserial-3.5-py2.py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting pyshark==0.6 (from -r ../requirements.txt (line 17))\n",
      "  Downloading pyshark-0.6-py3-none-any.whl.metadata (806 bytes)\n",
      "Collecting python-dotenv==1.1.0 (from -r ../requirements.txt (line 18))\n",
      "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: PyYAML==6.0.2 in /home/ubuntu/.venv/lib/python3.12/site-packages (from -r ../requirements.txt (line 19)) (6.0.2)\n",
      "Collecting streamlit==1.44.1 (from -r ../requirements.txt (line 20))\n",
      "  Downloading streamlit-1.44.1-py3-none-any.whl.metadata (8.9 kB)\n",
      "Collecting watchdog==6.0.0 (from -r ../requirements.txt (line 21))\n",
      "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
      "Collecting english-words==2.0.1 (from -r ../requirements.txt (line 22))\n",
      "  Downloading english-words-2.0.1.tar.gz (8.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m82.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tqdm==4.66.5 (from -r ../requirements.txt (line 23))\n",
      "  Downloading tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting typeguard==4.3.0 (from -r ../requirements.txt (line 24))\n",
      "  Downloading typeguard-4.3.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: requests>=1.0 in /home/ubuntu/.venv/lib/python3.12/site-packages (from python-gitlab==1.0.2->-r ../requirements.txt (line 3)) (2.32.5)\n",
      "Requirement already satisfied: six in /home/ubuntu/.venv/lib/python3.12/site-packages (from python-gitlab==1.0.2->-r ../requirements.txt (line 3)) (1.17.0)\n",
      "Collecting future (from gpudb==7.2.2.7->-r ../requirements.txt (line 4))\n",
      "  Downloading future-1.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: pyzmq in /home/ubuntu/.venv/lib/python3.12/site-packages (from gpudb==7.2.2.7->-r ../requirements.txt (line 4)) (27.1.0)\n",
      "Collecting sqlparse (from gpudb==7.2.2.7->-r ../requirements.txt (line 4))\n",
      "  Downloading sqlparse-0.5.3-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: decorator in /home/ubuntu/.venv/lib/python3.12/site-packages (from ipython==8.27.0->-r ../requirements.txt (line 5)) (5.2.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/ubuntu/.venv/lib/python3.12/site-packages (from ipython==8.27.0->-r ../requirements.txt (line 5)) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /home/ubuntu/.venv/lib/python3.12/site-packages (from ipython==8.27.0->-r ../requirements.txt (line 5)) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /home/ubuntu/.venv/lib/python3.12/site-packages (from ipython==8.27.0->-r ../requirements.txt (line 5)) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/ubuntu/.venv/lib/python3.12/site-packages (from ipython==8.27.0->-r ../requirements.txt (line 5)) (2.19.2)\n",
      "Requirement already satisfied: stack-data in /home/ubuntu/.venv/lib/python3.12/site-packages (from ipython==8.27.0->-r ../requirements.txt (line 5)) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in /home/ubuntu/.venv/lib/python3.12/site-packages (from ipython==8.27.0->-r ../requirements.txt (line 5)) (5.14.3)\n",
      "Collecting langsmith>=0.3.45 (from langchain_core==0.3.75->-r ../requirements.txt (line 6))\n",
      "  Downloading langsmith-0.4.29-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain_core==0.3.75->-r ../requirements.txt (line 6))\n",
      "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain_core==0.3.75->-r ../requirements.txt (line 6))\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /home/ubuntu/.venv/lib/python3.12/site-packages (from langchain_core==0.3.75->-r ../requirements.txt (line 6)) (4.15.0)\n",
      "Requirement already satisfied: packaging>=23.2 in /home/ubuntu/.venv/lib/python3.12/site-packages (from langchain_core==0.3.75->-r ../requirements.txt (line 6)) (25.0)\n",
      "Collecting pydantic>=2.7.4 (from langchain_core==0.3.75->-r ../requirements.txt (line 6))\n",
      "  Downloading pydantic-2.11.9-py3-none-any.whl.metadata (68 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.9.1 (from langchain_nvidia_ai_endpoints==0.3.9->-r ../requirements.txt (line 7))\n",
      "  Downloading aiohttp-3.12.15-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting langgraph-checkpoint<3.0.0,>=2.0.10 (from langgraph==0.3.34->-r ../requirements.txt (line 8))\n",
      "  Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting langgraph-prebuilt<0.2,>=0.1.8 (from langgraph==0.3.34->-r ../requirements.txt (line 8))\n",
      "  Downloading langgraph_prebuilt-0.1.8-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting langgraph-sdk<0.2.0,>=0.1.42 (from langgraph==0.3.34->-r ../requirements.txt (line 8))\n",
      "  Downloading langgraph_sdk-0.1.74-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting xxhash<4.0.0,>=3.5.0 (from langgraph==0.3.34->-r ../requirements.txt (line 8))\n",
      "  Downloading xxhash-3.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib==3.10.1->-r ../requirements.txt (line 9))\n",
      "  Downloading contourpy-1.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib==3.10.1->-r ../requirements.txt (line 9))\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib==3.10.1->-r ../requirements.txt (line 9))\n",
      "  Downloading fonttools-4.60.0-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (111 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib==3.10.1->-r ../requirements.txt (line 9))\n",
      "  Downloading kiwisolver-1.4.9-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.3 kB)\n",
      "Collecting pillow>=8 (from matplotlib==3.10.1->-r ../requirements.txt (line 9))\n",
      "  Downloading pillow-11.3.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (9.0 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib==3.10.1->-r ../requirements.txt (line 9))\n",
      "  Downloading pyparsing-3.2.4-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/ubuntu/.venv/lib/python3.12/site-packages (from matplotlib==3.10.1->-r ../requirements.txt (line 9)) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas==2.2.3->-r ../requirements.txt (line 11))\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas==2.2.3->-r ../requirements.txt (line 11))\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting bcrypt>=3.2 (from paramiko==3.5.1->-r ../requirements.txt (line 12))\n",
      "  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
      "Collecting cryptography>=3.3 (from paramiko==3.5.1->-r ../requirements.txt (line 12))\n",
      "  Downloading cryptography-46.0.1-cp311-abi3-manylinux_2_34_x86_64.whl.metadata (5.7 kB)\n",
      "Collecting pynacl>=1.5 (from paramiko==3.5.1->-r ../requirements.txt (line 12))\n",
      "  Downloading pynacl-1.6.0-cp38-abi3-manylinux_2_34_x86_64.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/ubuntu/.venv/lib/python3.12/site-packages (from pexpect==4.9.0->-r ../requirements.txt (line 13)) (0.7.0)\n",
      "Collecting lxml (from pyshark==0.6->-r ../requirements.txt (line 17))\n",
      "  Downloading lxml-6.0.1-cp312-cp312-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting termcolor (from pyshark==0.6->-r ../requirements.txt (line 17))\n",
      "  Downloading termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting appdirs (from pyshark==0.6->-r ../requirements.txt (line 17))\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting altair<6,>=4.0 (from streamlit==1.44.1->-r ../requirements.txt (line 20))\n",
      "  Downloading altair-5.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting blinker<2,>=1.0.0 (from streamlit==1.44.1->-r ../requirements.txt (line 20))\n",
      "  Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting cachetools<6,>=4.0 (from streamlit==1.44.1->-r ../requirements.txt (line 20))\n",
      "  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting click<9,>=7.0 (from streamlit==1.44.1->-r ../requirements.txt (line 20))\n",
      "  Downloading click-8.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting packaging>=23.2 (from langchain_core==0.3.75->-r ../requirements.txt (line 6))\n",
      "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting protobuf<6,>=3.20 (from streamlit==1.44.1->-r ../requirements.txt (line 20))\n",
      "  Downloading protobuf-5.29.5-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Collecting pyarrow>=7.0 (from streamlit==1.44.1->-r ../requirements.txt (line 20))\n",
      "  Downloading pyarrow-21.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting toml<2,>=0.10.1 (from streamlit==1.44.1->-r ../requirements.txt (line 20))\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit==1.44.1->-r ../requirements.txt (line 20))\n",
      "  Downloading gitpython-3.1.45-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pydeck<1,>=0.8.0b4 (from streamlit==1.44.1->-r ../requirements.txt (line 20))\n",
      "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in /home/ubuntu/.venv/lib/python3.12/site-packages (from streamlit==1.44.1->-r ../requirements.txt (line 20)) (6.5.2)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints==0.3.9->-r ../requirements.txt (line 7))\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints==0.3.9->-r ../requirements.txt (line 7))\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ubuntu/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints==0.3.9->-r ../requirements.txt (line 7)) (25.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints==0.3.9->-r ../requirements.txt (line 7))\n",
      "  Downloading frozenlist-1.7.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints==0.3.9->-r ../requirements.txt (line 7))\n",
      "  Downloading multidict-6.6.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints==0.3.9->-r ../requirements.txt (line 7))\n",
      "  Downloading propcache-0.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints==0.3.9->-r ../requirements.txt (line 7))\n",
      "  Downloading yarl-1.20.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (73 kB)\n",
      "Requirement already satisfied: jinja2 in /home/ubuntu/.venv/lib/python3.12/site-packages (from altair<6,>=4.0->streamlit==1.44.1->-r ../requirements.txt (line 20)) (3.1.6)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /home/ubuntu/.venv/lib/python3.12/site-packages (from altair<6,>=4.0->streamlit==1.44.1->-r ../requirements.txt (line 20)) (4.25.1)\n",
      "Collecting narwhals>=1.14.2 (from altair<6,>=4.0->streamlit==1.44.1->-r ../requirements.txt (line 20))\n",
      "  Downloading narwhals-2.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit==1.44.1->-r ../requirements.txt (line 20))\n",
      "  Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit==1.44.1->-r ../requirements.txt (line 20))\n",
      "  Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/ubuntu/.venv/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain_core==0.3.75->-r ../requirements.txt (line 6)) (3.0.0)\n",
      "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph==0.3.34->-r ../requirements.txt (line 8))\n",
      "  Downloading ormsgpack-1.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
      "Requirement already satisfied: httpx>=0.25.2 in /home/ubuntu/.venv/lib/python3.12/site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph==0.3.34->-r ../requirements.txt (line 8)) (0.28.1)\n",
      "Collecting orjson>=3.10.1 (from langgraph-sdk<0.2.0,>=0.1.42->langgraph==0.3.34->-r ../requirements.txt (line 8))\n",
      "  Downloading orjson-3.11.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: wcwidth in /home/ubuntu/.venv/lib/python3.12/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython==8.27.0->-r ../requirements.txt (line 5)) (0.2.13)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ubuntu/.venv/lib/python3.12/site-packages (from requests>=1.0->python-gitlab==1.0.2->-r ../requirements.txt (line 3)) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ubuntu/.venv/lib/python3.12/site-packages (from requests>=1.0->python-gitlab==1.0.2->-r ../requirements.txt (line 3)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ubuntu/.venv/lib/python3.12/site-packages (from requests>=1.0->python-gitlab==1.0.2->-r ../requirements.txt (line 3)) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/.venv/lib/python3.12/site-packages (from requests>=1.0->python-gitlab==1.0.2->-r ../requirements.txt (line 3)) (2025.8.3)\n",
      "Requirement already satisfied: cffi>=2.0.0 in /home/ubuntu/.venv/lib/python3.12/site-packages (from cryptography>=3.3->paramiko==3.5.1->-r ../requirements.txt (line 12)) (2.0.0)\n",
      "Requirement already satisfied: pycparser in /home/ubuntu/.venv/lib/python3.12/site-packages (from cffi>=2.0.0->cryptography>=3.3->paramiko==3.5.1->-r ../requirements.txt (line 12)) (2.23)\n",
      "Requirement already satisfied: anyio in /home/ubuntu/.venv/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph==0.3.34->-r ../requirements.txt (line 8)) (4.10.0)\n",
      "Requirement already satisfied: httpcore==1.* in /home/ubuntu/.venv/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph==0.3.34->-r ../requirements.txt (line 8)) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /home/ubuntu/.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph==0.3.34->-r ../requirements.txt (line 8)) (0.16.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /home/ubuntu/.venv/lib/python3.12/site-packages (from jedi>=0.16->ipython==8.27.0->-r ../requirements.txt (line 5)) (0.8.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ubuntu/.venv/lib/python3.12/site-packages (from jinja2->altair<6,>=4.0->streamlit==1.44.1->-r ../requirements.txt (line 20)) (3.0.2)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/ubuntu/.venv/lib/python3.12/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.44.1->-r ../requirements.txt (line 20)) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/ubuntu/.venv/lib/python3.12/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.44.1->-r ../requirements.txt (line 20)) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/ubuntu/.venv/lib/python3.12/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.44.1->-r ../requirements.txt (line 20)) (0.27.1)\n",
      "Collecting requests-toolbelt>=1.0.0 (from langsmith>=0.3.45->langchain_core==0.3.75->-r ../requirements.txt (line 6))\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard>=0.23.0 (from langsmith>=0.3.45->langchain_core==0.3.75->-r ../requirements.txt (line 6))\n",
      "  Downloading zstandard-0.25.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2.7.4->langchain_core==0.3.75->-r ../requirements.txt (line 6))\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic>=2.7.4->langchain_core==0.3.75->-r ../requirements.txt (line 6))\n",
      "  Downloading pydantic_core-2.33.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic>=2.7.4->langchain_core==0.3.75->-r ../requirements.txt (line 6))\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/ubuntu/.venv/lib/python3.12/site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph==0.3.34->-r ../requirements.txt (line 8)) (1.3.1)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/ubuntu/.venv/lib/python3.12/site-packages (from stack-data->ipython==8.27.0->-r ../requirements.txt (line 5)) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/ubuntu/.venv/lib/python3.12/site-packages (from stack-data->ipython==8.27.0->-r ../requirements.txt (line 5)) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /home/ubuntu/.venv/lib/python3.12/site-packages (from stack-data->ipython==8.27.0->-r ../requirements.txt (line 5)) (0.2.3)\n",
      "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Downloading gpudb-7.2.2.7-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (737 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m737.1/737.1 kB\u001b[0m \u001b[31m94.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ipython-8.27.0-py3-none-any.whl (818 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.0/819.0 kB\u001b[0m \u001b[31m88.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.3.75-py3-none-any.whl (443 kB)\n",
      "Downloading langchain_nvidia_ai_endpoints-0.3.9-py3-none-any.whl (41 kB)\n",
      "Downloading langgraph-0.3.34-py3-none-any.whl (148 kB)\n",
      "Downloading matplotlib-3.10.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m119.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m126.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m96.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading paramiko-3.5.1-py3-none-any.whl (227 kB)\n",
      "Downloading PyMySQL-1.1.1-py3-none-any.whl (44 kB)\n",
      "Downloading pyroute2-0.9.2-py3-none-any.whl (474 kB)\n",
      "Downloading pyserial-3.5-py2.py3-none-any.whl (90 kB)\n",
      "Downloading pyshark-0.6-py3-none-any.whl (41 kB)\n",
      "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
      "Downloading streamlit-1.44.1-py3-none-any.whl (9.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m120.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
      "Downloading tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
      "Downloading typeguard-4.3.0-py3-none-any.whl (35 kB)\n",
      "Downloading aiohttp-3.12.15-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m135.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading altair-5.5.0-py3-none-any.whl (731 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.2/731.2 kB\u001b[0m \u001b[31m94.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Downloading click-8.3.0-py3-none-any.whl (107 kB)\n",
      "Downloading gitpython-3.1.45-py3-none-any.whl (208 kB)\n",
      "Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl (43 kB)\n",
      "Downloading langgraph_prebuilt-0.1.8-py3-none-any.whl (25 kB)\n",
      "Downloading langgraph_sdk-0.1.74-py3-none-any.whl (50 kB)\n",
      "Downloading multidict-6.6.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (256 kB)\n",
      "Downloading packaging-24.2-py3-none-any.whl (65 kB)\n",
      "Downloading pillow-11.3.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-5.29.5-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
      "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m92.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Downloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Downloading xxhash-3.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Downloading yarl-1.20.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (355 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n",
      "Downloading contourpy-1.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (362 kB)\n",
      "Downloading cryptography-46.0.1-cp311-abi3-manylinux_2_34_x86_64.whl (4.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m119.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.60.0-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m96.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading frozenlist-1.7.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (241 kB)\n",
      "Downloading kiwisolver-1.4.9-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m108.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langsmith-0.4.29-py3-none-any.whl (386 kB)\n",
      "Downloading pydantic-2.11.9-py3-none-any.whl (444 kB)\n",
      "Downloading pydantic_core-2.33.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m130.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading narwhals-2.5.0-py3-none-any.whl (407 kB)\n",
      "Downloading orjson-3.11.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (132 kB)\n",
      "Downloading ormsgpack-1.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (216 kB)\n",
      "Downloading propcache-0.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (224 kB)\n",
      "Downloading pyarrow-21.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (42.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m89.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pynacl-1.6.0-cp38-abi3-manylinux_2_34_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m132.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.2.4-py3-none-any.whl (113 kB)\n",
      "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Downloading zstandard-0.25.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m148.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading future-1.0.0-py3-none-any.whl (491 kB)\n",
      "Downloading lxml-6.0.1-cp312-cp312-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl (5.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m150.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sqlparse-0.5.3-py3-none-any.whl (44 kB)\n",
      "Downloading termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
      "Building wheels for collected packages: python-gitlab, english-words\n",
      "  Building wheel for python-gitlab (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for python-gitlab: filename=python_gitlab-1.0.2-py3-none-any.whl size=77949 sha256=9be0d81b478581b3994d2cd566cbacf5e9f1ca6e235173bd11a70749370e180b\n",
      "  Stored in directory: /ephemeral/cache/pip/wheels/af/84/b2/dcaf0b3a657a50870332113bcf95a028cea142a72aad5d6b6c\n",
      "  Building wheel for english-words (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for english-words: filename=english_words-2.0.1-py3-none-any.whl size=8196319 sha256=fd7a54f6bffee7121e61dbd70bb84169b13aa5ec8058d4e2e3b3ba98ea8fc8a6\n",
      "  Stored in directory: /ephemeral/cache/pip/wheels/c6/c2/43/dfc6b3dfd9cefbd45a4f9886f6fa6b174b78833860d972f988\n",
      "Successfully built python-gitlab english-words\n",
      "Installing collected packages: pytz, pyserial, pyroute2, english-words, appdirs, zstandard, xxhash, watchdog, tzdata, typing-inspection, typeguard, tqdm, toml, termcolor, tenacity, sqlparse, smmap, python-dotenv, pyparsing, pymysql, pydantic-core, pyarrow, protobuf, propcache, pillow, packaging, ormsgpack, orjson, numpy, narwhals, multidict, lxml, kiwisolver, jsonpatch, future, frozenlist, fonttools, cycler, colorlog, colorama, click, cachetools, blinker, bcrypt, annotated-types, aiohappyeyeballs, yarl, requests-toolbelt, python-gitlab, pyshark, pynacl, pydeck, pydantic, pandas, ipython, gpudb, gitdb, cryptography, contourpy, aiosignal, paramiko, matplotlib, langsmith, langgraph-sdk, gitpython, aiohttp, langchain_core, altair, streamlit, langgraph-checkpoint, langchain_nvidia_ai_endpoints, langgraph-prebuilt, langgraph\n",
      "\u001b[2K  Attempting uninstall: packaging0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24/73\u001b[0m [pillow]f]core]\n",
      "\u001b[2K    Found existing installation: packaging 25.0━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24/73\u001b[0m [pillow]\n",
      "\u001b[2K    Uninstalling packaging-25.0:[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24/73\u001b[0m [pillow]\n",
      "\u001b[2K      Successfully uninstalled packaging-25.0━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24/73\u001b[0m [pillow]\n",
      "\u001b[2K  Attempting uninstall: ipython━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m53/73\u001b[0m [pandas]c]tlab]\n",
      "\u001b[2K    Found existing installation: ipython 9.5.0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m53/73\u001b[0m [pandas]\n",
      "\u001b[2K    Uninstalling ipython-9.5.0:━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m53/73\u001b[0m [pandas]\n",
      "\u001b[2K      Successfully uninstalled ipython-9.5.0[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m53/73\u001b[0m [pandas]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73/73\u001b[0m [langgraph]anggraph]treamlit]core]\n",
      "\u001b[1A\u001b[2KSuccessfully installed aiohappyeyeballs-2.6.1 aiohttp-3.12.15 aiosignal-1.4.0 altair-5.5.0 annotated-types-0.7.0 appdirs-1.4.4 bcrypt-4.3.0 blinker-1.9.0 cachetools-5.5.2 click-8.3.0 colorama-0.4.6 colorlog-6.9.0 contourpy-1.3.3 cryptography-46.0.1 cycler-0.12.1 english-words-2.0.1 fonttools-4.60.0 frozenlist-1.7.0 future-1.0.0 gitdb-4.0.12 gitpython-3.1.45 gpudb-7.2.2.7 ipython-8.27.0 jsonpatch-1.33 kiwisolver-1.4.9 langchain_core-0.3.75 langchain_nvidia_ai_endpoints-0.3.9 langgraph-0.3.34 langgraph-checkpoint-2.1.1 langgraph-prebuilt-0.1.8 langgraph-sdk-0.1.74 langsmith-0.4.29 lxml-6.0.1 matplotlib-3.10.1 multidict-6.6.4 narwhals-2.5.0 numpy-1.26.4 orjson-3.11.3 ormsgpack-1.10.0 packaging-24.2 pandas-2.2.3 paramiko-3.5.1 pillow-11.3.0 propcache-0.3.2 protobuf-5.29.5 pyarrow-21.0.0 pydantic-2.11.9 pydantic-core-2.33.2 pydeck-0.9.1 pymysql-1.1.1 pynacl-1.6.0 pyparsing-3.2.4 pyroute2-0.9.2 pyserial-3.5 pyshark-0.6 python-dotenv-1.1.0 python-gitlab-1.0.2 pytz-2025.2 requests-toolbelt-1.0.0 smmap-5.0.2 sqlparse-0.5.3 streamlit-1.44.1 tenacity-9.1.2 termcolor-3.1.0 toml-0.10.2 tqdm-4.66.5 typeguard-4.3.0 typing-inspection-0.4.1 tzdata-2025.2 watchdog-6.0.0 xxhash-3.5.0 yarl-1.20.1 zstandard-0.25.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##%%capture\n",
    "!sudo apt install -y iperf3\n",
    "%pip install -r ../requirements.txt\n",
    "import IPython\n",
    "IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing Flexric and gNodeB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code will take between 7 and 8 minutes to run. It  will compile the ric and gNodeB components within the DLI environment. If you want to install this lab in your computer, you just need to download the DLI directory and execute this command. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!chmod +x build_ric_oai_ne.sh\n",
    "!./build_ric_oai_ne.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing Kinetika Database Instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code will  install Kinetica Local Database "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!chmod +x run_kinetica_headless.sh\n",
    "!./run_kinetica_headless.sh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OAI 5G Network \n",
    "To set up the 5G core Network funcitons we will use the docker compose comand. First, we will setup the standard network funciton for the core and then we will set up an additonal slice (slice 2) that will have its own SMF and UPF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!docker compose --progress=plain -f docker-compose-oai-cn-slice1.yaml up -d\n",
    "import time\n",
    "time.sleep(20)\n",
    "!docker compose --progress=plain -f docker-compose-oai-cn-slice2.yaml up -d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start RIC\n",
    "\n",
    "Then we will start the FlexRIC to be able to modify parameters in the gNodeB on an ad hoc basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process started with PID 148586, logging to logs/RIC.log.\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "# Ensure the logs directory exists\n",
    "os.makedirs(\"logs\", exist_ok=True)\n",
    "\n",
    "cmd = \"./flexric/build/examples/ric/nearRT-RIC\"\n",
    "logfile = \"logs/RIC.log\"\n",
    "\n",
    "# Open log file for writing and start the process\n",
    "with open(logfile, \"a\") as log:\n",
    "    process = subprocess.Popen(\n",
    "        [\"bash\", \"-c\", f\"stdbuf -oL {cmd}\"],  # stdbuf ensures real-time logging\n",
    "        stdout=log,\n",
    "        stderr=subprocess.STDOUT,\n",
    "        universal_newlines=True\n",
    "    )\n",
    "\n",
    "print(f\"Process started with PID {process.pid}, logging to {logfile}.\")\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>Trouble Shooting - Sample output</summary>\n",
    "  \n",
    "  If flexric starts successfully you should see a similar output in logs/RIC.log\n",
    "  ```\n",
    "  [UTIL]: Setting the config -c file to /usr/local/etc/flexric/flexric.conf\n",
    "[UTIL]: Setting path -p for the shared libraries to /usr/local/lib/flexric/\n",
    "[NEAR-RIC]: nearRT-RIC IP Address = 127.0.0.1, PORT = 36421\n",
    "[NEAR-RIC]: Initializing \n",
    "[NEAR-RIC]: Loading SM ID = 142 with def = MAC_STATS_V0 \n",
    "[NEAR-RIC]: Loading SM ID = 143 with def = RLC_STATS_V0 \n",
    "[NEAR-RIC]: Loading SM ID = 3 with def = ORAN-E2SM-RC \n",
    "[NEAR-RIC]: Loading SM ID = 146 with def = TC_STATS_V0 \n",
    "[NEAR-RIC]: Loading SM ID = 148 with def = GTP_STATS_V0 \n",
    "[NEAR-RIC]: Loading SM ID = 145 with def = SLICE_STATS_V0 \n",
    "[NEAR-RIC]: Loading SM ID = 2 with def = ORAN-E2SM-KPM \n",
    "[NEAR-RIC]: Loading SM ID = 144 with def = PDCP_STATS_V0 \n",
    "[iApp]: Initializing ... \n",
    "[iApp]: nearRT-RIC IP Address = 127.0.0.1, PORT = 36422\n",
    "[NEAR-RIC]: Initializing Task Manager with 2 threads \n",
    "[E2AP]: E2 SETUP-REQUEST rx from PLMN   1. 1 Node ID 3584 RAN type ngran_gNB\n",
    "[NEAR-RIC]: Accepting RAN function ID 2 with def = ORAN-E2SM-KPM \n",
    "[NEAR-RIC]: Accepting RAN function ID 3 with def = ORAN-E2SM-RC \n",
    "[NEAR-RIC]: Accepting RAN function ID 142 with def = MAC_STATS_V0 \n",
    "[NEAR-RIC]: Accepting RAN function ID 143 with def = RLC_STATS_V0 \n",
    "[NEAR-RIC]: Accepting RAN function ID 144 with def = PDCP_STATS_V0 \n",
    "[NEAR-RIC]: Accepting RAN function ID 145 with def = SLICE_STATS_V0 \n",
    "[NEAR-RIC]: Accepting RAN function ID 146 with def = TC_STATS_V0 \n",
    "[NEAR-RIC]: Accepting RAN function ID 148 with def = GTP_STATS_V0 \n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start the gNodeB\n",
    "Then we will run the gNodeB using the OAI softmoden software"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process started with PID 149062, logging to logs/gNodeB.log.\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "cmd = \"sudo ./openairinterface5g/cmake_targets/ran_build/build/nr-softmodem -O ran-conf/gnb.conf --sa --rfsim -E --gNBs.[0].min_rxtxtime 6\"\n",
    "logfile = \"logs/gNodeB.log\"\n",
    "\n",
    "env = os.environ.copy()\n",
    "env[\"LD_LIBRARY_PATH\"] = \".\"\n",
    "\n",
    "# Open log file for writing and start the process\n",
    "with open(logfile, \"a\") as log:\n",
    "    process = subprocess.Popen(\n",
    "        [\"bash\", \"-c\", f\"stdbuf -oL {cmd}\"],  # stdbuf ensures real-time logging\n",
    "        stdout=log,\n",
    "        stderr=subprocess.STDOUT,\n",
    "        universal_newlines=True\n",
    "    )\n",
    "\n",
    "print(f\"Process started with PID {process.pid}, logging to {logfile}.\")\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Bandwidth 50 50 \n",
    "The gNodeB will have initially allocated 50% of its bandwidth to each of the slices. \n",
    "\n",
    "- Note : Incase you get `[E2AP]: Resending Setup Request after timeout`error, rerun the `Start RIC` cell.\n",
    "\n",
    "***\n",
    "Please check `./logs/RIC.log` to ensure that flexRIC is working. Incase you see a \"failed\" message, try rerunning the `Start RIC` cell above. \n",
    "\n",
    "Error message : \n",
    "```\n",
    "nearRT-RIC: /dli/task/llm-slicing-5g-lab/flexric/src/lib/e2ap/v2_03/enc/e2ap_msg_enc_asn.c:3165: e2ap_enc_e42_setup_response_asn_pdu: Assertion `sr->len_e2_nodes_conn > 0 && \"No global node conected??\"' failed.\n",
    "```\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50+50\n",
      "[UTIL]: Setting the config -c file to /usr/local/etc/flexric/flexric.conf\n",
      "[UTIL]: Setting path -p for the shared libraries to /usr/local/lib/flexric/\n",
      "[xAapp]: Initializing ... \n",
      "[xApp]: nearRT-RIC IP Address = 127.0.0.1, PORT = 36422\n",
      "[E2 AGENT]: Opening plugin from path = /usr/local/lib/flexric/libkpm_sm.so \n",
      "[E2 AGENT]: Opening plugin from path = /usr/local/lib/flexric/librlc_sm.so \n",
      "[E2 AGENT]: Opening plugin from path = /usr/local/lib/flexric/libpdcp_sm.so \n",
      "[E2 AGENT]: Opening plugin from path = /usr/local/lib/flexric/libgtp_sm.so \n",
      "[E2 AGENT]: Opening plugin from path = /usr/local/lib/flexric/libtc_sm.so \n",
      "[E2 AGENT]: Opening plugin from path = /usr/local/lib/flexric/librc_sm.so \n",
      "[E2 AGENT]: Opening plugin from path = /usr/local/lib/flexric/libslice_sm.so \n",
      "[E2 AGENT]: Opening plugin from path = /usr/local/lib/flexric/libmac_sm.so \n",
      "[NEAR-RIC]: Loading SM ID = 2 with def = ORAN-E2SM-KPM \n",
      "[NEAR-RIC]: Loading SM ID = 143 with def = RLC_STATS_V0 \n",
      "[NEAR-RIC]: Loading SM ID = 144 with def = PDCP_STATS_V0 \n",
      "[NEAR-RIC]: Loading SM ID = 148 with def = GTP_STATS_V0 \n",
      "[NEAR-RIC]: Loading SM ID = 146 with def = TC_STATS_V0 \n",
      "[NEAR-RIC]: Loading SM ID = 3 with def = ORAN-E2SM-RC \n",
      "[NEAR-RIC]: Loading SM ID = 145 with def = SLICE_STATS_V0 \n",
      "[NEAR-RIC]: Loading SM ID = 142 with def = MAC_STATS_V0 \n",
      "[xApp]: DB filename = /tmp/xapp_db_1758298539056190 \n",
      " [xApp]: E42 SETUP-REQUEST tx\n",
      "[xApp]: E42 SETUP-RESPONSE rx \n",
      "[xApp]: xApp ID = 7 \n",
      "[xApp]: Registered E2 Nodes = 1 \n",
      "Connected E2 nodes = 1\n",
      "Setting PRB Ratio to 50:50\n",
      "[xApp]: CONTROL-REQUEST tx \n",
      "[xApp]: CONTROL ACK rx\n",
      "[xApp]: Successfully received CONTROL-ACK \n",
      "[xApp]: Control Loop Latency: 1082 us\n",
      "[xApp]: Sucessfully stopped \n",
      "Test xApp run SUCCESSFULLY\n"
     ]
    }
   ],
   "source": [
    "!./change_rc_slice.sh 50 50\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start the UE\n",
    "After we will create a User Equipment Simulator and attach it to the gNodeB. Following cell creates UE1 and UE2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import subprocess\n",
    "import logging\n",
    "from typing import Optional, List\n",
    "\n",
    "import colorlog\n",
    "\n",
    "# Configure colored logging.\n",
    "handler = colorlog.StreamHandler()\n",
    "handler.setFormatter(colorlog.ColoredFormatter(\n",
    "    fmt=\"%(log_color)s%(asctime)s %(levelname)s: %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    "    log_colors={\n",
    "        'DEBUG':    'blue',\n",
    "        'INFO':     'green',\n",
    "        'WARNING':  'yellow',\n",
    "        'ERROR':    'red',\n",
    "        'CRITICAL': 'red,bg_white',\n",
    "    }\n",
    "))\n",
    "logger = colorlog.getLogger(__name__)\n",
    "logger.addHandler(handler)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.propagate = False\n",
    "\n",
    "def start_async_process(name: str, cmd: str, logfile: str) -> Optional[subprocess.Popen]:\n",
    "    \"\"\"\n",
    "    Start an asynchronous process and log its status.\n",
    "\n",
    "    Args:\n",
    "        name: Name of the process.\n",
    "        cmd: The command to run.\n",
    "        logfile: Path to the log file.\n",
    "\n",
    "    Returns:\n",
    "        The subprocess.Popen object if the process started successfully;\n",
    "        None otherwise.\n",
    "    \"\"\"\n",
    "    logger.info(\"Starting process %s with command: %s\", name, cmd)\n",
    "    try:\n",
    "        with open(logfile, \"a\") as log:\n",
    "            process = subprocess.Popen(\n",
    "                [\"bash\", \"-c\", f\"stdbuf -oL {cmd}\"],\n",
    "                stdout=log,\n",
    "                stderr=subprocess.STDOUT,\n",
    "                universal_newlines=True,\n",
    "            )\n",
    "        if process.pid:\n",
    "            logger.info(\"Process %s started with PID %s, logging to %s\", name, process.pid, logfile)\n",
    "            return process\n",
    "        else:\n",
    "            logger.error(\"Process %s did not start properly.\", name)\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        logger.error(\"Failed to start process %s: %s\", name, str(e))\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-19 16:15:51 INFO: Starting process UE1 with command: \n",
      "    sudo ./multi_ue.sh -c1 -e & \n",
      "    sleep 5\n",
      "    sudo ip netns exec ue1 bash -c '\n",
      "        sudo LD_LIBRARY_PATH=. ./openairinterface5g/cmake_targets/ran_build/build/nr-uesoftmodem \\\n",
      "        --rfsimulator.serveraddr 10.201.1.100 -r 106 --numerology 1 --band 78 -C 3619200000 \\\n",
      "        --rfsim --sa -O ran-conf/ue_1.conf -E\n",
      "    '\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-09-19 16:15:51 INFO: Process UE1 started with PID 150406, logging to logs/UE1.log\u001b[0m\n",
      "\u001b[32m2025-09-19 16:15:51 INFO: Starting process UE3 with command: \n",
      "    sudo ./multi_ue.sh -c3 -e & \n",
      "    sleep 5\n",
      "    sudo ip netns exec ue3 bash -c '\n",
      "        sudo LD_LIBRARY_PATH=. ./openairinterface5g/cmake_targets/ran_build/build/nr-uesoftmodem \\\n",
      "        --rfsimulator.serveraddr 10.203.1.100 -r 106 --numerology 1 --band 78 -C 3619200000 \\\n",
      "        --rfsim --sa -O ran-conf/ue_2.conf -E\n",
      "    '\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-09-19 16:15:51 INFO: Process UE3 started with PID 150407, logging to logs/UE3.log\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    sudo ./multi_ue.sh -c1 -e & \n",
      "    sleep 5\n",
      "    sudo ip netns exec ue1 bash -c '\n",
      "        sudo LD_LIBRARY_PATH=. ./openairinterface5g/cmake_targets/ran_build/build/nr-uesoftmodem \\\n",
      "        --rfsimulator.serveraddr 10.201.1.100 -r 106 --numerology 1 --band 78 -C 3619200000 \\\n",
      "        --rfsim --sa -O ran-conf/ue_1.conf -E\n",
      "    '\n",
      "    \n",
      "\n",
      "    sudo ./multi_ue.sh -c3 -e & \n",
      "    sleep 5\n",
      "    sudo ip netns exec ue3 bash -c '\n",
      "        sudo LD_LIBRARY_PATH=. ./openairinterface5g/cmake_targets/ran_build/build/nr-uesoftmodem \\\n",
      "        --rfsimulator.serveraddr 10.203.1.100 -r 106 --numerology 1 --band 78 -C 3619200000 \\\n",
      "        --rfsim --sa -O ran-conf/ue_2.conf -E\n",
      "    '\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "def start_ue(ue_id: str, config_file: str, namespace: str, server_addr: str, port: str = \"106\") -> Optional[subprocess.Popen]:\n",
    "    \"\"\"\n",
    "    Start a UE process.\n",
    "\n",
    "    Args:\n",
    "        ue_id: Identifier for the UE (used in command arguments and logging).\n",
    "        config_file: Path to the UE configuration file.\n",
    "        namespace: The network namespace for the UE.\n",
    "        server_addr: The server address for the UE.\n",
    "        port: The port used by the UE (default is \"106\").\n",
    "\n",
    "    Returns:\n",
    "        The subprocess.Popen object if the process started successfully; None otherwise.\n",
    "    \"\"\"\n",
    "    cmd = f\"\"\"\n",
    "    sudo ./multi_ue.sh -c{ue_id} -e & \n",
    "    sleep 5\n",
    "    sudo ip netns exec {namespace} bash -c '\n",
    "        sudo LD_LIBRARY_PATH=. ./openairinterface5g/cmake_targets/ran_build/build/nr-uesoftmodem \\\\\n",
    "        --rfsimulator.serveraddr {server_addr} -r {port} --numerology 1 --band 78 -C 3619200000 \\\\\n",
    "        --rfsim --sa -O {config_file} -E\n",
    "    '\n",
    "    \"\"\"\n",
    "    logfile = f\"logs/UE{ue_id}.log\"\n",
    "    print(cmd)\n",
    "    return start_async_process(f\"UE{ue_id}\", cmd, logfile)\n",
    "\n",
    "ue1_process = start_ue(\"1\", \"ran-conf/ue_1.conf\", \"ue1\", \"10.201.1.100\")\n",
    "ue2_process = start_ue(\"3\", \"ran-conf/ue_2.conf\", \"ue3\", \"10.203.1.100\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Debugging tip: Print logs for sanity check**\n",
    "\n",
    "```\n",
    "tail -f logs/UE1.log\n",
    "tail -f logs/UE3.log\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start the Iperf Tool Server\n",
    "Once the 5G Network Simulation is running we will start the simulation of traffic by using with tool Iperf. First we will create an Iperf Server that will be on the External Network connected via the User Plane Function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-19 16:15:55 INFO: Starting process iPerf_server1 with command: docker exec -t oai-ext-dn iperf3 -s -p 5201\u001b[0m\n",
      "\u001b[32m2025-09-19 16:15:55 INFO: Process iPerf_server1 started with PID 150589, logging to logs/docker_iperfserver_server1.log\u001b[0m\n",
      "\u001b[32m2025-09-19 16:15:55 INFO: Starting process iPerf_server2 with command: docker exec -t oai-ext-dn iperf3 -s -p 5202\u001b[0m\n",
      "\u001b[32m2025-09-19 16:15:55 INFO: Process iPerf_server2 started with PID 150590, logging to logs/docker_iperfserver_server2.log\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def start_iperf(name: str, port: str) -> Optional[subprocess.Popen]:\n",
    "    \"\"\"\n",
    "    Start an iPerf3 server process.\n",
    "\n",
    "    Args:\n",
    "        name: Identifier for the iPerf3 instance.\n",
    "        port: Port on which the iPerf3 server should run.\n",
    "\n",
    "    Returns:\n",
    "        The subprocess.Popen object if started successfully; None otherwise.\n",
    "    \"\"\"\n",
    "    cmd = f\"docker exec -t oai-ext-dn iperf3 -s -p {port}\"\n",
    "    logfile = f\"logs/docker_iperfserver_{name}.log\"\n",
    "    return start_async_process(f\"iPerf_{name}\", cmd, logfile)\n",
    "\n",
    "iperf1_process = start_iperf(\"server1\", \"5201\")\n",
    "iperf2_process = start_iperf(\"server2\", \"5202\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Traffic generator and insert records in the database\n",
    "Once every element in The Network is up and running and the Iperf server is listening in the external network. We will run two iperf clients that will be generating traffic in both UEs. These scripts will generate udp traffic from the iperf server towards the UE and will alternate speeds 30M and 120M for 100 seconds. In the following cell we will\n",
    "\n",
    "1. Run traffic generator to alternate between 30M and 120M\n",
    "2. Insert UE1 and UE2 iperf logs into the Kinetica Database. Kinetica is a very fast, distributed, GPU-accelerated database with advanced analytics, visualization, geospatial, and machine learning functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate traffic \n",
    "\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "import subprocess\n",
    "import threading\n",
    "from typing import Dict, List, Pattern\n",
    "\n",
    "from dotenv import load_dotenv, set_key\n",
    "from english_words import get_english_words_set\n",
    "import gpudb\n",
    "from gpudb import GPUdb\n",
    "from gpudb import GPUdbColumnProperty as cp\n",
    "from gpudb import GPUdbRecordColumn as rc\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "\n",
    "class IperfRecord:\n",
    "    def __init__(\n",
    "        self,\n",
    "        record_id: str = \"\",\n",
    "        record_ue: str = None,\n",
    "        record_timestamp: str = \"\",\n",
    "        record_stream: int = None,\n",
    "        record_interval_start: float = None,\n",
    "        record_interval_end: float = None,\n",
    "        record_duration: float = 0.0,\n",
    "        record_data_transferred: float = None,\n",
    "        record_bitrate: float = None,\n",
    "        record_jitter: float = None,\n",
    "        record_lost_packets: int = None,\n",
    "        record_total_packets: int = None,\n",
    "        record_loss_percentage: float = None\n",
    "    ) -> None:\n",
    "        self.id = record_id\n",
    "        self.ue = record_ue\n",
    "        self.timestamp = record_timestamp\n",
    "        self.stream = record_stream\n",
    "        self.interval_start = record_interval_start\n",
    "        self.interval_end = record_interval_end\n",
    "        self.duration = record_duration\n",
    "        self.data_transferred = record_data_transferred\n",
    "        self.bitrate = record_bitrate\n",
    "        self.jitter = record_jitter\n",
    "        self.lost_packets = record_lost_packets\n",
    "        self.total_packets = record_total_packets\n",
    "        self.loss_percentage = record_loss_percentage\n",
    "\n",
    "    def record_to_dict(self) -> Dict[str, str | float]:\n",
    "        return {\n",
    "            \"id\": self.id,\n",
    "            \"ue\": self.ue,\n",
    "            \"timestamp\": self.timestamp,\n",
    "            \"stream\": self.stream,\n",
    "            \"interval_start\": self.interval_start,\n",
    "            \"interval_end\": self.interval_end,\n",
    "            \"duration\": self.duration,\n",
    "            \"data_transferred\": self.data_transferred,\n",
    "            \"bitrate\": self.bitrate,\n",
    "            \"jitter\": self.jitter,\n",
    "            \"lost_packets\": self.lost_packets,\n",
    "            \"total_packets\": self.total_packets,\n",
    "            \"loss_percentage\": self.loss_percentage\n",
    "        }\n",
    "\n",
    "\n",
    "def convert_bandwidth(bw_str: str) -> int:\n",
    "    \"\"\"\n",
    "    Converts a bandwidth string like \"120M\" or \"30M\" into an integer in bits per second.\n",
    "    \"\"\"\n",
    "    if bw_str.endswith(\"M\"):\n",
    "        return int(bw_str[:-1]) * 1_000_000\n",
    "    elif bw_str.endswith(\"K\"):\n",
    "        return int(bw_str[:-1]) * 1_000\n",
    "    else:\n",
    "        return int(bw_str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Error: 'dict' object is not callable\n",
      "✅ Schema 'nvidia_gtc_dli_2025' created successfully\n",
      "📋 Using fixed table name: nvidia_gtc_dli_2025.iperf3_logs\n",
      "   This ensures compatibility with Python scripts without environment variable issues\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <b>Kinetica Table:</b> <a target=\"_blank\" href=\"http://localhost:8080/gadmin/#/table/nvidia_gtc_dli_2025/iperf3_logs\">iperf3_logs</a> </br>\n",
       "    <b>User:</b> admin </br>\n",
       "    <b>Password:</b> Admin123! </br>\n",
       "    <b>Local Kinetica Admin Console:</b> <a target=\"_blank\" href=\"http://localhost:8080/gadmin\">http://localhost:8080/gadmin</a>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-19 16:17:38 INFO: CURRENT ITERATION: 0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load environment variables and initialize Kinetica connection.\n",
    "# Configure for local Kinetica instance\n",
    "os.environ[\"KINETICA_HOST\"] = \"localhost:9191\"\n",
    "os.environ[\"KINETICA_USERNAME\"] = \"admin\"\n",
    "os.environ[\"KINETICA_PASSWORD\"] = \"Admin123!\"\n",
    "os.environ[\"KINETICA_SCHEMA\"] = \"nvidia_gtc_dli_2025\"\n",
    "\n",
    "kdbc_options = GPUdb.Options()\n",
    "kdbc_options.username = os.environ.get(\"KINETICA_USERNAME\")\n",
    "kdbc_options.password = os.environ.get(\"KINETICA_PASSWORD\")\n",
    "kdbc_options.disable_auto_discovery = True\n",
    "word_list: List[str] = list(get_english_words_set(['web2'], lower=True))\n",
    "\n",
    "\n",
    "def generate_random_table_name() -> str:\n",
    "    # Use a fixed table name instead of random - much simpler and more reliable!\n",
    "    fixed_table_name = \"nvidia_gtc_dli_2025.iperf3_logs\"\n",
    "    \n",
    "    print(f\"📋 Using fixed table name: {fixed_table_name}\")\n",
    "    print(\"   This ensures compatibility with Python scripts without environment variable issues\")\n",
    "    \n",
    "    return fixed_table_name\n",
    "\n",
    "kdbc: GPUdb = GPUdb(\n",
    "    host=os.environ.get(\"KINETICA_HOST\"),\n",
    "    options=kdbc_options\n",
    ")\n",
    "\n",
    "target_schema = \"nvidia_gtc_dli_2025\"\n",
    "\n",
    "try:\n",
    "    # List existing schemas\n",
    "    schemas = kdbc.gpudb_schemas()\n",
    "    print(f\"📋 Found {len(schemas)} existing schemas\")\n",
    "    \n",
    "    # Check if target schema exists\n",
    "    schema_exists = any(s['schema_name'] == target_schema for s in schemas)\n",
    "    \n",
    "    if schema_exists:\n",
    "        print(f\"✅ Schema '{target_schema}' already exists\")\n",
    "    else:\n",
    "        print(f\"�� Creating schema '{target_schema}'...\")\n",
    "        kdbc.create_schema(target_schema)\n",
    "        print(f\"✅ Schema '{target_schema}' created successfully\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error: {e}\")\n",
    "    # Fallback: try direct creation\n",
    "    try:\n",
    "        kdbc.create_schema(target_schema)\n",
    "        print(f\"✅ Schema '{target_schema}' created successfully\")\n",
    "    except Exception as e2:\n",
    "        if \"already exists\" in str(e2).lower():\n",
    "            print(f\"✅ Schema '{target_schema}' already exists\")\n",
    "        else:\n",
    "            raise Exception(f\"Cannot create schema: {e2}\")\n",
    "            \n",
    "\n",
    "iperf3_table_name: str = generate_random_table_name()\n",
    "if kdbc.has_table(table_name=iperf3_table_name).table_exists:\n",
    "    kdbc.clear_table(table_name=iperf3_table_name)\n",
    "\n",
    "schema, table = iperf3_table_name.split('.')\n",
    "url = f'http://localhost:8080/gadmin/#/table/{schema}/{table}'\n",
    "user = os.environ.get(\"KINETICA_USERNAME\")\n",
    "password = os.environ.get(\"KINETICA_PASSWORD\")\n",
    "html_out = f'''\n",
    "    <b>Kinetica Table:</b> <a target=\"_blank\" href=\"{url}\">{table}</a> </br>\n",
    "    <b>User:</b> {user} </br>\n",
    "    <b>Password:</b> {password} </br>\n",
    "    <b>Local Kinetica Admin Console:</b> <a target=\"_blank\" href=\"http://localhost:8080/gadmin\">http://localhost:8080/gadmin</a>\n",
    "'''\n",
    "display(HTML(html_out))\n",
    "\n",
    "schema: List[List[str]] = [\n",
    "    [\"id\",               rc._ColumnType.STRING, cp.UUID,     cp.PRIMARY_KEY, cp.INIT_WITH_UUID],\n",
    "    [\"ue\",               rc._ColumnType.STRING, cp.CHAR8,    cp.DICT],\n",
    "    [\"timestamp\",        rc._ColumnType.STRING, cp.DATETIME, cp.INIT_WITH_NOW],\n",
    "    [\"stream\",           rc._ColumnType.INT,    cp.INT8,     cp.DICT],\n",
    "    [\"interval_start\",   rc._ColumnType.FLOAT],\n",
    "    [\"interval_end\",     rc._ColumnType.FLOAT],\n",
    "    [\"duration\",         rc._ColumnType.FLOAT],\n",
    "    [\"data_transferred\", rc._ColumnType.FLOAT],\n",
    "    [\"bitrate\",          rc._ColumnType.FLOAT],\n",
    "    [\"jitter\",           rc._ColumnType.FLOAT],\n",
    "    [\"lost_packets\",     rc._ColumnType.INT],\n",
    "    [\"total_packets\",    rc._ColumnType.INT],\n",
    "    [\"loss_percentage\",  rc._ColumnType.FLOAT]\n",
    "]\n",
    "kdbc_table = gpudb.GPUdbTable(\n",
    "    _type=schema,\n",
    "    name=iperf3_table_name,\n",
    "    db=kdbc\n",
    ")\n",
    "\n",
    "# Precompiled regex pattern to parse iperf3 output.\n",
    "filter_regex: str = (\n",
    "    r'^\\[ *([0-9]+)\\] +([0-9]+\\.[0-9]+)-([0-9]+\\.[0-9]+) +sec +'\n",
    "    r'([0-9\\.]+) +MBytes +([0-9\\.]+) +Mbits/sec +([0-9\\.]+) +ms +'\n",
    "    r'([0-9]+)/([0-9]+) +\\(([0-9\\.]+)%\\)$'\n",
    ")\n",
    "pattern: Pattern[str] = re.compile(filter_regex)\n",
    "\n",
    "\n",
    "def iperf_runner(\n",
    "    namespace: str,\n",
    "    ue_name: str,\n",
    "    bind_host: str,\n",
    "    server_host: str,\n",
    "    udp_port: int,\n",
    "    bandwidth: str,\n",
    "    test_length_secs: int,\n",
    "    kdbc_table: gpudb.GPUdbTable,\n",
    "    pattern: Pattern[str],\n",
    "    log_file: str\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Runs iperf for one UE, parses and inserts records into Kinetica,\n",
    "    and writes each record to a dedicated log file in the specified format.\n",
    "    Exits when the iperf process finishes.\n",
    "\n",
    "    :param namespace: The network namespace for the UE.\n",
    "    :param ue_name: A label/identifier for the UE (e.g., \"UE1\").\n",
    "    :param bind_host: IP address to bind to (iperf3 -B).\n",
    "    :param server_host: The remote iperf3 server IP address.\n",
    "    :param udp_port: The UDP port to use (iperf3 -p).\n",
    "    :param bandwidth: The bandwidth limit (e.g. \"30M\" or \"120M\").\n",
    "    :param test_length_secs: The test duration in seconds (iperf3 -t).\n",
    "    :param kdbc_table: The Kinetica table object where we insert records.\n",
    "    :param pattern: Precompiled regex to parse iperf3 output.\n",
    "    :param log_file: Path to the log file for this iperf3 process (e.g. \"logs/UE1_iperfc.log\").\n",
    "    \"\"\"\n",
    "    try:\n",
    "        iperf_cmd = (\n",
    "            f\"stdbuf -oL iperf3 \"\n",
    "            f\"-B {bind_host} \"\n",
    "            f\"-c {server_host} \"\n",
    "            f\"-p {udp_port} \"\n",
    "            f\"-R -u \"\n",
    "            f\"-b {bandwidth} \"\n",
    "            f\"-t {test_length_secs}\"\n",
    "        )\n",
    "        cmd = [\"sudo\", \"ip\", \"netns\", \"exec\", namespace, \"bash\", \"-c\", iperf_cmd]\n",
    "\n",
    "        # Open a subprocess to run iperf3.\n",
    "        with subprocess.Popen(\n",
    "            cmd,\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.STDOUT,\n",
    "            universal_newlines=True,\n",
    "            bufsize=1\n",
    "        ) as proc:\n",
    "            for line in proc.stdout:\n",
    "                line = line.strip()\n",
    "                match = pattern.match(line)\n",
    "                if match:\n",
    "                    # Create an IperfRecord from the parsed line.\n",
    "                    iperf_record = IperfRecord(\n",
    "                        record_ue=ue_name,\n",
    "                        record_stream=int(match.group(1)),\n",
    "                        record_interval_start=float(match.group(2)),\n",
    "                        record_interval_end=float(match.group(3)),\n",
    "                        record_data_transferred=float(match.group(4)),\n",
    "                        record_bitrate=float(match.group(5)),\n",
    "                        record_jitter=float(match.group(6)),\n",
    "                        record_lost_packets=int(match.group(7)),\n",
    "                        record_total_packets=int(match.group(8)),\n",
    "                        record_loss_percentage=float(match.group(9))\n",
    "                    )\n",
    "                    # Calculate duration.\n",
    "                    iperf_record.duration = iperf_record.interval_end - iperf_record.interval_start\n",
    "\n",
    "                    # Insert record into Kinetica.\n",
    "                    record_dict = iperf_record.record_to_dict()\n",
    "                    kdbc_table.insert_records(record_dict)\n",
    "                    kdbc_table.flush_data_to_server()\n",
    "\n",
    "                    # Write the raw iperf3 output line to the dedicated log file\n",
    "                    # with the format: \"[<UE>] [<timestamp>] <line>\"\n",
    "                    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                    with open(log_file, \"a\") as f:\n",
    "                        f.write(f\"[{ue_name}] [{timestamp}] {line}\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error running process: {e}\")\n",
    "    # When iperf3 ends, the function exits so that the main thread can handle any post-run activities.\n",
    "\n",
    "\n",
    "bandwidth_ue1: str = \"30M\"\n",
    "bandwidth_ue2: str = \"120M\"\n",
    "bind_host_ue1: str = \"12.1.1.2\"\n",
    "bind_host_ue2: str = \"12.1.1.130\"\n",
    "server_host_ue1: str = \"192.168.70.135\"\n",
    "server_host_ue2: str = \"192.168.70.135\"\n",
    "udp_port_ue1: int = 5201\n",
    "udp_port_ue2: int = 5202\n",
    "test_length_secs: int = 100\n",
    "\n",
    "test_iterations: int = 25 # Feel free to change this as you see fit to run the log generation for a longer period of time.\n",
    "current_iteration: int = 0\n",
    "\n",
    "while current_iteration < test_iterations:\n",
    "    logger.info(f\"\"\"CURRENT ITERATION: {current_iteration}\"\"\")\n",
    "    current_iteration += 1\n",
    "    \n",
    "    t1: threading.Thread = threading.Thread(\n",
    "        target=iperf_runner,\n",
    "        args=(\n",
    "            \"ue1\",\n",
    "            \"UE1\",\n",
    "            bind_host_ue1,\n",
    "            server_host_ue1,\n",
    "            udp_port_ue1,\n",
    "            bandwidth_ue1,\n",
    "            test_length_secs,\n",
    "            kdbc_table,\n",
    "            pattern,\n",
    "            \"logs/UE1_iperfc.log\"\n",
    "        ),\n",
    "        daemon=True\n",
    "    )\n",
    "\n",
    "    t2: threading.Thread = threading.Thread(\n",
    "        target=iperf_runner,\n",
    "        args=(\n",
    "            \"ue3\",\n",
    "            \"UE3\",\n",
    "            bind_host_ue2,\n",
    "            server_host_ue2,\n",
    "            udp_port_ue2,\n",
    "            bandwidth_ue2,\n",
    "            test_length_secs,\n",
    "            kdbc_table,\n",
    "            pattern,\n",
    "            \"logs/UE2_iperfc.log\"\n",
    "        ),\n",
    "        daemon=True\n",
    "    )\n",
    "\n",
    "    t1.start()\n",
    "    t2.start()\n",
    "\n",
    "    t1.join()\n",
    "    t2.join()\n",
    "\n",
    "    if bandwidth_ue1 == \"30M\":\n",
    "        bandwidth_ue1 = \"120M\"\n",
    "    else:\n",
    "        bandwidth_ue1 = \"30M\"\n",
    "\n",
    "    if bandwidth_ue2 == \"30M\":\n",
    "        bandwidth_ue2 = \"120M\"\n",
    "    else:\n",
    "        bandwidth_ue2 = \"30M\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep the above cell running! If you want to see what is happening in the background, you can:\n",
    "1. Check out UE1, UE2 iperf logs to see how traffic generator works, and how it leads to packet loss:\n",
    "    ```bash\n",
    "    tail -f logs/UE1_iperfc.log\n",
    "    tail -f logs/UE2_iperfc.log\n",
    "    ```\n",
    "\n",
    "2. Access Kinetica database, and see how wlogs are updated there real-time. Login with your username and password for the local instance.\n",
    "\n",
    "    - KINETICA_USERNAME=\"admin\"\n",
    "    - KINETICA_PASSWORD=\"Admin123!\"\n",
    "    - KINETICA_SCHEMA=\"nvidia_gtc_dli_2025\"\n",
    "    - Table name: os.environment.get(\"IPERF3_RANDOM_TABLE_NAME\")\n",
    "    - URL : http://localhost:8080/gadmin/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will be the final step setting up the 5G Lab for the Agentic Workflow.\n",
    "\n",
    "![stop](./Stop2.jpg) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
